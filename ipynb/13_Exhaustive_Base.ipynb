{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "# Find the base for various number of mixture signals. Add the avlternative vase features sequentially and select them according to the approximation to the external error."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:10:23.248141Z",
     "start_time": "2025-03-25T23:10:22.662668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from functions import *\n",
    "from dataload import load_data, get_clusters, gen_base, next_sample_dset\n",
    "from experiment import FeatureSelection\n",
    "\n",
    "# Load data and data basis\n",
    "iqdata, iqnoise = load_data()\n",
    "dbasis = get_clusters()\n",
    "\n",
    "# Create a data generator and the main class instance\n",
    "# The indices of base centroids in iqdata\n",
    "idx_basis = list(dbasis.keys())\n",
    "Abase = iqdata[idx_basis].transpose()\n",
    "\n",
    "# How to use the data:\n",
    "\n",
    "# Generate new dset with randomly mixed signals as y plus a noise of desired level\n",
    "class_sizes = [0, 0, 0, 0, 0, 100]  # Set sample size for i-th collision\n",
    "# dset = gen_base(iqdata, iqnoise, dbasis, cls_sizes)\n",
    "# print(list(dset[0].keys())) # List of the keys in each data sample\n",
    "\n",
    "# To get the data in easy way while setting noise, use the function\n",
    "def get_dset(noise_lvl):\n",
    "    # The arguments of the called function is in the cell visibility\n",
    "    # We suppose they do not change during the experiment\n",
    "    dset = gen_base(iqdata, iqnoise, dbasis, cls_sizes=class_sizes, noise_level=noise_lvl)\n",
    "    return dset\n",
    "\n",
    "# This instance delivers the new y with answers\n",
    "# next_sample = next_sample_dset(dset, idx_basis) # Use after generation new dset\n",
    "\n",
    "# This instance carry models for each y\n",
    "# fs = FeatureSelection(Abase) # Use after get a new y"
   ],
   "id": "f5131307cd5a78b1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:10:25.462081Z",
     "start_time": "2025-03-25T23:10:25.458607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The parameters of the computational experiment\n",
    "n_models = 6\n",
    "n_classes = len(class_sizes)\n",
    "# Later we check the reconstructed signal with one of the cluster's signals"
   ],
   "id": "95b0b86593610c30",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:10:27.497886Z",
     "start_time": "2025-03-25T23:10:26.757675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate the new noisy dset of mixtures and create a datasample generator\n",
    "noise_coeff = 1.0\n",
    "db = get_dset(noise_coeff)\n",
    "next_sample = next_sample_dset(db, idx_basis)"
   ],
   "id": "9a55a9ecb77e33fc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:11:08.196396Z",
     "start_time": "2025-03-25T23:10:39.291472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the reconstruction quality\n",
    "cnt_err = 0\n",
    "cnt_resolved = 0\n",
    "X_cls = np.empty([0,n_models * n_classes])  # objects to 4 class classification\n",
    "X_cls_haus = X_cls.copy()\n",
    "\n",
    "y_cls = []  # target 4 classes\n",
    "for i in range(100):\n",
    "    # Get a sample from the dataset\n",
    "    answer_y, answer_X, answer_A, answer_coeff, answer_shift = next(next_sample)\n",
    "    fs = FeatureSelection(Abase, max_models = n_models ) # Reset the list of models\n",
    "    fs.MAX_MODELS = n_models\n",
    "    fs.MAX_BASIS = 1\n",
    "\n",
    "    # Run the reconstruction procedure\n",
    "    # fs.mdl = run(fs.A, answer_y, fs.mdl, max_basis=5, max_models=6)\n",
    "    i_dist = np.array([])\n",
    "    i_haus = i_dist.copy()\n",
    "    # For each number of collided signals\n",
    "    for c in range(n_classes):\n",
    "        fs.run(answer_y)\n",
    "        i_dist = np.hstack((i_dist, np.array([values['err'] for values in fs.mdl.values()])))\n",
    "        # Use alternative error, too\n",
    "        fs.update_error(answer_y)\n",
    "        i_haus = np.hstack((i_dist, np.array([values['err'] for values in fs.mdl.values()])))\n",
    "        # print(np.shape(i_dist))\n",
    "    # Make the dataset for classification\n",
    "    X_cls = np.vstack((X_cls, i_dist.transpose()))\n",
    "    X_cls_haus = np.vstack((X_cls, i_haus.transpose()))\n",
    "    y_cls.append(len(answer_A))\n",
    "    # construct\n",
    "\n",
    "    # Plot the best model\n",
    "    # fs.plot_mdl(answer_y, 1)\n",
    "    # Check the quality of the reconstruction by comparing with the answer\n",
    "    best_A = fs.best_model()['fea']\n",
    "    dist = fs.best_model()['err']\n",
    "    if set(answer_A) == set(best_A):\n",
    "        print(i, 'errors:', dist)\n",
    "    else:\n",
    "        cnt_err += 1\n",
    "        print(i, 'errors:', dist, 'answer:', answer_A, 'model:', best_A)\n",
    "    len_resolved = len(set(answer_A) & set(best_A))\n",
    "    if len_resolved > 0:\n",
    "        cnt_resolved += 1\n",
    "        print(i, 'resolved:', len_resolved)\n",
    "print('_____________________')\n",
    "print(cnt_err , cnt_resolved)\n",
    "\n"
   ],
   "id": "56aab7ea7f58900f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 36 and the array at index 1 has size 42",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 29\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# print(np.shape(i_dist))\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Make the dataset for classification\u001B[39;00m\n\u001B[1;32m     28\u001B[0m X_cls \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack((X_cls, i_dist\u001B[38;5;241m.\u001B[39mtranspose()))\n\u001B[0;32m---> 29\u001B[0m X_cls_haus \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_cls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi_haus\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m y_cls\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mlen\u001B[39m(answer_A))\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# construct\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Plot the best model\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# fs.plot_mdl(answer_y, 1)\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Check the quality of the reconstruction by comparing with the answer\u001B[39;00m\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mvstack\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/core/shape_base.py:296\u001B[0m, in \u001B[0;36mvstack\u001B[0;34m(tup, dtype, casting)\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arrs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    295\u001B[0m     arrs \u001B[38;5;241m=\u001B[39m [arrs]\n\u001B[0;32m--> 296\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 36 and the array at index 1 has size 42"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5f4129921da02d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
